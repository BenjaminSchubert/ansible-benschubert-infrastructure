{{ template_warning }}
{% set job_name = "prometheus.scrape.host" %}
{% set log_instance = "(instance {{ $labels.instance }})" %}
{% set log_values_and_labels = "VALUE = {{ $value }}\\n  LABELS = {{ $labels }}" %}
groups:
- name: host
  interval: 60s
  rules:
  ##
  # Alerts to ensure the prometheus jobs are running properly
  ##
  - alert: AlloyPrometheusJobMissing
    expr: absent(up{job="{{ job_name }}"})
    for: 0m
    labels:
      severity: critical
    annotations:
      summary: A Prometheus job is missing {{ log_instance }}
      description: A Prometheus job did not report metrics\n  {{ log_values_and_labels }}

  - alert: InstanceDown
    expr: up{job="{{ job_name }}"} == 0
    for: 0m
    labels:
      severity: critical
    annotations:
      summary: An instance is down {{ log_instance }}
      description: An instance is down.\n  {{ log_values_and_labels }}

  - alert: PrometheusTemplateTextExpansionFailures
    expr: increase(prometheus_template_text_expansion_failures_total{job="{{ job_name }}"}[3m]) > 0
    for: 0m
    labels:
      severity: critical
    annotations:
      summary: Prometheus template text expansion failures {{ log_instance }}
      description: Prometheus encountered {{ '{{' }} $value {{ '}}' }} template text expansion failures\n  {{ log_values_and_labels }}

  - alert: PrometheusTargetScrapingSlow
    expr: prometheus_target_interval_length_seconds{job="{{ job_name }}", quantile="0.9"} / on (interval, instance, job) prometheus_target_interval_length_seconds{job="{{ job_name }}", quantile="0.5"} > 1.05
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: Prometheus target scraping slow {{ log_instance }}
      description: Prometheus exceeded the requested interval time to scrape a target. It might need more resources.\n  {{ log_values_and_labels }}

  - alert: PrometheusLargeScrape
    expr: increase(prometheus_target_scrapes_exceeded_sample_limit_total{job="{{ job_name }}"}[10m]) > 10
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: Prometheus large scrape {{ log_instance }}
      description: Prometheus has many scrapes that exceed the sample limit\n  {{ log_values_and_labels }}

  ##
  # Alloy
  ##
  - alert: AlloyTooManyRestarts
    expr: changes(alloy_resources_process_start_time_seconds{job="{{ job_name }}"}[5m]) > 2
    for: 0m
    labels:
      severity: warning
    annotations:
      summary: Alloy too many restarts {{ log_instance }}
      description: Grafana Alloy has restarted more than twice in the last 5 minutes. It might be crashlooping.\n  {{ log_values_and_labels }}

  - alert: AlloyConfigurationReloadFailure
    expr: alloy_config_last_load_successful{job="{{ job_name }}"} != 1
    for: 0m
    labels:
      severity: warning
    annotations:
      summary: Grafana Alloy configuration reload failure {{ log_instance }}
      description: Grafana Alloy failed to reload a configuration file\n  {{ log_values_and_labels }}

  - alert: GrafanaAlloyTargetScrapeDuplicate
    expr: increase(prometheus_target_scrapes_sample_duplicate_timestamp_total{job="{{ job_name }}"}[5m]) > 0
    for: 0m
    labels:
      severity: warning
    annotations:
      summary: Grafana Alloy target scrape duplicate {{ log_instance }}
      description: Grafana Alloy had samples rejected due to duplicate timestamps but different values\n  {{ log_values_and_labels }}

  ##
  # Alerts for Loki
  ##
  - alert: GrafanaAlloyLokiUnableToPublishLogs
    expr: loki_write_dropped_entries_total{job="{{ job_name }}"} > 0
    for: 0m
    labels:
      severity: critical
    annotations:
      summary: Loki exporter was unable to write to Loki {{ log_instance }}
      description: Grafana Alloy's Loki exporter was unable to write to Loki remotely. Logs and alerts were logs\n {{ log_values_and_labels }}

  ##
  # Alerts for the node-exporter
  ##
  - alert: NodeExporterJobMissing
    expr: absent(up{job="integrations/unix"})
    for: 0m
    labels:
      severity: critical
    annotations:
      summary: A Prometheus job is missing {{ log_instance }}
      description: A Prometheus job did not report metrics\n  {{ log_values_and_labels }}

  - alert: InstanceDown
    expr: up{job="integrations/unix"} == 0
    for: 0m
    labels:
      severity: critical
    annotations:
      summary: An instance is down {{ log_instance }}
      description: An instance is down.\n  {{ log_values_and_labels }}
